### 1.Concept

>Unlike traditional regression that calculates loss for any difference between predicted and true values, Support Vector Regression assumes we can tolerate a deviation of $\epsilon$ between f(x) and y. Loss is only incurred when the absolute difference is greater than $\epsilon$
### 2.Sparsity

>The final SVR model is also sparse and depends only on a portion of the training samples

### 3.Kernelization

>SVR can also be kernelized, allowing it to handle non-linear regression tasks.