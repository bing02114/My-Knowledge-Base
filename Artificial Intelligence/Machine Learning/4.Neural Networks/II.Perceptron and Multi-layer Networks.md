### 1.Perceptron

>A perceptron is composed of two layers of neurons: an input layer that receives external signals and an output layer of M-P neurons, also known as "threshold logic units".


### 2.Learning Capability

>A single-layer perceptron can only solve linearly separable problems (e.g., AND, OR, NOT). It cannot solve non-linearly separable problems, such as the XOR problem


### 3.Multi-layer Networks

>To solve non-linearly separable problems, multi-layer functional neurons are required

* **Hidden-Layer**: The layer of neurons between the input and output layers is called the hidden layer
* **Multi-layer Feedforward Neural Network**: A common network structure where each layer of neurons is fully connected to the next layer, with no connections within the same layer or across non-adjacent layers. What the network "learns" is stored in the connection weights and thresholds