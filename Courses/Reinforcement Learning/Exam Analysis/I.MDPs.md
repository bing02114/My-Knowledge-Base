### 考点1 马尔可夫性质

**定义**

* 马尔可夫性质的定义与解释

**应用**

* 不同模型对马尔可夫性质的利用/是否使用了马尔可夫性质

### 考点2 折扣因子

**折扣因子与状态价值**

* 折扣因子对于价值函数收敛性的影响

**折扣因子与优化目标**

* 最优策略的目标是获得最大化长期**折损**累计增益

### 考点3 状态/状态空间


### 考点4 动作/动作空间


### 考点5 奖励/奖励函数

**与环境的关系**

* 联合环境/环境转移概率与奖励函数的关系

### 考点6 回报/折损累计增益

**回报的随机性**

* 单个轨迹的回报是具有随机性的

### 考点7 环境转移概率

**联合转移概率**

* 联合 (joint) 环境转移概率 p(s',r|s,a) 能够完整反映环境动态
* 联合环境/环境转移概率与奖励函数的关系

* 随机性在环境转移概率中的影响

### 考点8 策略

**策略与转移概率**

*  区分策略和状态转移概率

**最优策略**

* 最优策略的性质（不一共是确定性策略、不一定唯一）

**策略提升定理**

* 理解策略提升定理，不会出现价值降低，新策略大于等于原策略

**提取最优策略**

* 从状态/动作价值函数中计算策略

**策略与随机性**

* 随机性策略的定义

### 考点9 状态价值函数

**性质**

* 最优价值函数的性质（有且仅有一个）

**定义**

* 状态价值函数的意义（期望），不是一个episode的实际回报

### 考点10 动作价值函数

**计算**

* 会计算指定MDP的动作价值函数

**定义**

*  动作价值Q函数的定义

### 考点11 贝尔曼方程

**计算**

* 指定MDP/MRP贝尔曼期望方程（状态/动作）的计算

**公式**

* 贝尔曼期望方程的迭代式展开（包含多种展开方式）

**扩展**

* r和γ都为1时，贝尔曼状态价值变为到达终点的期望步数（计算）
* 方差的贝尔曼方程（推导/计算步数的方差）

**性质**

* 贝尔曼方程与最优子结构

### 考点12 最优性

**定义**

* 贝尔曼最优性原理、贝尔曼最优性的定义
* 贝尔曼最优方程和贝尔曼方程的区别

**公式**

* 贝尔曼最优方程的多种表示方式
* 最优价值函数与最优动作函数的相等以及这种相等关系的表示公式

### 考点13 马尔可夫决策过程

**基础概念**

*  马尔可夫过程、马尔可夫奖励过程、马尔可夫决策过程、隐马尔科夫模型(HMM)、部分可观测马尔可夫决策过程(POMDF)的基础理解
* MDP与MRP的区分

**目标**

* 马尔可夫决策过程的目标

**绘图**

* 会计算所有需要的值并绘图