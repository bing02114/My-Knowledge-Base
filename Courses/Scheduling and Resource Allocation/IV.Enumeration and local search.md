### 1.Solving NP-hard Scheduling Problems

>The document begins by stating that most scheduling problems are NP-hard, meaning they cannot be solved efficiently for large-scale instances. These problems are framed as combinatorial optimization problems, where the goal is to find a schedule 'S' that minimizes a cost function, often an additive one like g(S)=∑j​gj​(S).

Three main types of techniques are introduced to address these problems:

* **Approximation algorithms**: Methods that provide formal performance guarantees.
* **Enumeration methods**: Exhaustive search techniques that guarantee finding a global optimum if given enough time.
* **Metaheuristics**: Heuristic methods that quickly find good solutions, which are typically local optima, with performance validated experimentally


### 2.Enumeration Methods

This category includes methods that systematically explore the entire solution space to find the absolute best solution.

#### 2.1 Dynamic Programming

>This is an exhaustive enumeration method that recursively solves subproblems to find the optimal solution. It uses Bellman's value equation, G(J)=minj∈J​{G(J−j)+gj​(J)}, to calculate the minimum cost for scheduling a set of jobs 'J'. The computational complexity of this method is high, typically O(n2n) for 'n' jobs, making it suitable only for small problems.

#### 2.2 Branch and Bound

This is another common enumeration method that consists of two main procedures:

* **Branching**: This process partitions the main problem into smaller, more manageable subproblems, which can be visualized as a search tree.
* **Bounding**: For each subproblem (or node in the tree), a lower bound on the best possible cost is calculated. If a node's lower bound is worse than the best solution found so far, that entire branch of the tree can be "pruned" or discarded (a process called fathoming), significantly reducing the search space. The algorithm often explores the node with the smallest lower bound first, a strategy known as "jumptracking"

#### 2.3 Metaheuristics

>These are advanced heuristics designed to find high-quality solutions to optimization problems without exhaustively searching the entire solution space.

**a) Local Search**

Local search is a heuristic that works by iteratively moving from a current solution 'S' to a better one within its "neighborhood" N(S). A neighborhood is often generated by making small changes, such as an adjacent pairwise interchange of jobs. The primary weakness of this method is its tendency to get trapped in local optima, which are solutions that are better than their neighbors but not the global best.

**b) Simulated Annealing**

SA is a metaheuristic designed to escape local optima. It explores the solution space via a random walk. While it always accepts moves to better solutions, it can also accept moves to _worse_ solutions with a certain probability, eΔ/Tk​, where Δ is the negative change in cost and Tk​ is a "temperature" parameter. The temperature gradually decreases over time according to a cooling schedule (e.g., Tk+1​=αTk​). As the temperature cools, the probability of accepting a worse solution decreases, causing the search to eventually converge on a good solution.

**c) Tabu Search**

Tabu search is a deterministic method for global optimization that also allows moves to worse solutions to escape local optima. Its key feature is the use of a memory structure called a **tabu list**. This list stores the last 'L' moves (e.g., job pairs that were swapped) and forbids them from being reversed for a certain number of iterations. This prevents the search from cycling between the same solutions and encourages exploration of new areas. An "aspiration criterion" can override the tabu status if a forbidden move leads to the best solution found so far.

**d) Handling Constraints**

The document concludes by discussing how to apply these methods to problems with constraints. Two main approaches are presented:

* **Rejection Method**: Candidate solutions that violate any constraints are simply discarded. This is most effective when feasible solutions are easy to find
* **Penalty Function Method**: The constrained problem is transformed into an unconstrained one by adding a penalty to the cost function for any constraint violations. The magnitude of the penalty is controlled by user-defined constants, which can be difficult to tune correctly
