### 1.Key Enabler of Deep Learning

>The truning point was AlexNet in 2012, which was trained on two NVIDIA 580 GPUs.
>
>This event highlighted the massive parallel processing power of GPUs, making them ideal for training deep neural networks

### 2.Domiant Vendor

>NVIDIA holds over 80% of the datacenter GPU market. Its dominance is largely due to its robust software ecosystem, CUDA, which includes optimized libraries (cuDNN, NCCL), and developer tools for profiling and debugging.

### 3.Why GPUs are Suitable for AI

>AI and deep learning workloads, such as Convolutional Neural Networks (CNNs) and Transformers, are fundamentally based on matrix multiplication and other linear algebra operations. These operations are highly parallelizable, making them a perfect match for the GPU's architecture.


### 4.CPU vs. GPU

>CPUs are designed for general-purpose, sequential tasks and have limited parallelism. GPUs, on the other hand, are designed for data-parallel tasks, executing the same operation on many data points simultaneously.

