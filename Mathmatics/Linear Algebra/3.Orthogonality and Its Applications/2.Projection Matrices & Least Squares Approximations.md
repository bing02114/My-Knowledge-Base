### 1.Properties of Projections

**Projection Matrix**

**$$P=A(A^{T}A)^{-1}A^{T}$$**
**Case1: b is in the Column Space C(A)**

>Pb will project b into the column space of Matrix A
>
>If the vector `b` is already in the column space of A (meaning Ax=b has a solution), then projecting `b` onto C(A) does not change it.

**Case2: b is Orthogonal to the Column Space**

>If `b` is orthogonal to the column space of A, it means `b` is in the left nullspace, N(Aᵀ).

***
### 2. The Method of Least Squares

#### 2.1 The Problem and Goal

**The Problem**

>When fitting a line (e.g., b=C+Dt) to a set of data points, we often get an overdetermined system of equations Ax=b that has no solution.

The Goal

>To find an optimal solution x^ that minimizes the sum of the squares of the errors,
>
>$$||e||^2=||Ax-b||^2$$

#### 2.2 The Solution: Geometric and Algebraic Views

**Geometric View**

>The optimal solution is found by projecting the data vector `b` onto the column space of A. 
>
>The resulting vector, $$p=A\hat{x}$$, is the point in C(A) closest to `b`. 
>
>The error vector `e = b - p` is orthogonal to the column space.

**Algebraic View**

>The optimal solution $$\hat{x}$$ is found by solving the **normal equation**:
>
>$$A^{T}A\hat{x}=A^{T}b$$
>

**Calculus View**

>Minimizing the error function E=∣∣Ax−b∣∣2 by taking partial derivatives with respect to the unknown coefficients and setting them to zero leads to the exact same normal equation.

### 2.3 The Invertibility of ATA

><font color="red">The ability to solve the normal equation uniquely depends on whether the matrix ATA is invertible.</font>

**The Theorem:**

>The matrix ATA is invertible if and only if the **columns of A are linearly independent**.

**Orthonormal Columns:**

>If the columns of a matrix are orthonormal, they are guaranteed to be linearly independent.
